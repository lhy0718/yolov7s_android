{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX to TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "2023-10-29 00:17:29.746185: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-29 00:17:34.887942: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: yolov7-tiny-tf-320/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: yolov7-tiny-tf-320/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import onnx\n",
    "import tensorflow as tf\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ['LD_LIBRARY_PATH'] = '${CONDA_PREFIX}/lib:${LD_LIBRARY_PATH}'\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto, InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "image_size = 320\n",
    "\n",
    "onnx_model_path = f\"yolov7-tiny_fp32_{image_size}.onnx\"\n",
    "tf_model_path = f\"yolov7-tiny-tf-{image_size}\"\n",
    "\n",
    "onnx_model = onnx.load(onnx_model_path)  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
    "tf_rep.export_graph(tf_model_path)  # export the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325 (1, 10, 10, 255)\n",
      "317 (1, 20, 20, 255)\n",
      "output (1, 40, 40, 255)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_shape = (1, 320, 320, 3)\n",
    "\n",
    "model = tf.saved_model.load(tf_model_path)\n",
    "model.trainable = False\n",
    "\n",
    "input_tensor = tf.random.uniform(input_shape, 0, 255)\n",
    "out = model(images=input_tensor)\n",
    "for k in out:\n",
    "    print(k, out[k].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 00:17:51.751457: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-10-29 00:17:51.751478: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2023-10-29 00:17:51.752111: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: yolov7-tiny-tf-320\n",
      "2023-10-29 00:17:51.760157: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2023-10-29 00:17:51.760178: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: yolov7-tiny-tf-320\n",
      "2023-10-29 00:17:51.772486: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-10-29 00:17:51.843314: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: yolov7-tiny-tf-320\n",
      "2023-10-29 00:17:51.925377: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 173270 microseconds.\n",
      "2023-10-29 00:17:52.012090: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-29 00:17:52.421285: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 3.438 G  ops, equivalently 1.719 G  MACs\n",
      "\n",
      "2023-10-29 00:17:52.440444: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor convolution because it has fewer than 1024 elements (864).\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated count of arithmetic ops: 3.438 G  ops, equivalently 1.719 G  MACs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tflite_model_path = f'yolov7-tiny_fp32_{image_size}.tflite'\n",
    "# tf_model_path = \"yolov7-tiny-tf\"\n",
    "\n",
    "# Convert\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "# model = tf.keras.models.load_model(tf_model_path, compile=False)\n",
    "# func = tf.function(model).get_concrete_function(\n",
    "#     images=tf.TensorSpec(input_shape, tf.float32)\n",
    "# )\n",
    "# converter = tf.lite.TFLiteConverter.from_concrete_functions([func])\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanyong/.local/lib/python3.8/site-packages/tensorflow_lite_support/metadata/python/metadata.py:395: UserWarning: File, 'label.txt', does not exist in the metadata. But packing it to tflite model is still allowed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "\"\"\" ... \"\"\"\n",
    "\"\"\"Creates the metadata for an image classifier.\"\"\"\n",
    "\n",
    "LABLE_FILE = os.path.basename('label.txt')\n",
    "\n",
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = tflite_model_path.split('.')[0]\n",
    "\n",
    "# Creates input info.\n",
    "input_meta = _metadata_fb.TensorMetadataT()\n",
    "input_meta.name = \"image\"\n",
    "input_meta.description = (\"image\")\n",
    "input_meta.content = _metadata_fb.ContentT()\n",
    "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "input_meta.content.contentProperties.colorSpace = (\n",
    "    _metadata_fb.ColorSpaceType.RGB)\n",
    "input_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.ImageProperties)\n",
    "input_normalization = _metadata_fb.ProcessUnitT()\n",
    "input_normalization.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
    "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "input_normalization.options.mean = [127.5]\n",
    "input_normalization.options.std = [127.5]\n",
    "input_meta.processUnits = [input_normalization]\n",
    "input_stats = _metadata_fb.StatsT()\n",
    "input_stats.max = [255]\n",
    "input_stats.min = [0]\n",
    "input_meta.stats = input_stats\n",
    "\n",
    "# Creates output info.\n",
    "output_location_meta = _metadata_fb.TensorMetadataT()\n",
    "output_location_meta.name = \"location\"\n",
    "output_location_meta.description = \"The locations of the detected boxes.\"\n",
    "output_location_meta.content = _metadata_fb.ContentT()\n",
    "output_location_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.BoundingBoxProperties)\n",
    "output_location_meta.content.contentProperties = (\n",
    "    _metadata_fb.BoundingBoxPropertiesT())\n",
    "output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
    "output_location_meta.content.contentProperties.type = (\n",
    "    _metadata_fb.BoundingBoxType.BOUNDARIES)\n",
    "output_location_meta.content.contentProperties.coordinateType = (\n",
    "    _metadata_fb.CoordinateType.RATIO)\n",
    "output_location_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_location_meta.content.range.min = 2\n",
    "output_location_meta.content.range.max = 2\n",
    "\n",
    "output_class_meta = _metadata_fb.TensorMetadataT()\n",
    "output_class_meta.name = \"category\"\n",
    "output_class_meta.description = \"The categories of the detected boxes.\"\n",
    "output_class_meta.content = _metadata_fb.ContentT()\n",
    "output_class_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_class_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "output_class_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_class_meta.content.range.min = 2\n",
    "output_class_meta.content.range.max = 2\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = LABLE_FILE\n",
    "label_file.description = \"Label of objects that this model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_AXIS_LABELS\n",
    "output_class_meta.associatedFiles = [label_file]\n",
    "\n",
    "output_score_meta = _metadata_fb.TensorMetadataT()\n",
    "output_score_meta.name = \"score\"\n",
    "output_score_meta.description = \"The scores of the detected boxes.\"\n",
    "output_score_meta.content = _metadata_fb.ContentT()\n",
    "output_score_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_score_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "output_score_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_score_meta.content.range.min = 2\n",
    "output_score_meta.content.range.max = 2\n",
    "\n",
    "output_number_meta = _metadata_fb.TensorMetadataT()\n",
    "output_number_meta.name = \"number of detections\"\n",
    "output_number_meta.description = \"The number of the detected boxes.\"\n",
    "output_number_meta.content = _metadata_fb.ContentT()\n",
    "output_number_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_number_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT()\n",
    ")\n",
    "\n",
    "output_identity_meta = _metadata_fb.TensorMetadataT()\n",
    "output_identity_meta.name = \"Identity\"\n",
    "output_identity_1_meta = _metadata_fb.TensorMetadataT()\n",
    "output_identity_1_meta.name = \"Identity_1\"\n",
    "output_identity_2_meta = _metadata_fb.TensorMetadataT()\n",
    "output_identity_2_meta.name = \"Identity_2\"\n",
    "\n",
    "# Creates subgraph info.\n",
    "subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "subgraph.inputTensorMetadata = [input_meta]\n",
    "# subgraph.outputTensorMetadata = [output_location_meta, output_score_meta, output_class_meta, output_number_meta]\n",
    "subgraph.outputTensorMetadata = [output_identity_meta, output_identity_1_meta, output_identity_2_meta]\n",
    "model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()\n",
    "\n",
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "\n",
    "populator = _metadata.MetadataPopulator.with_model_file(tflite_model_path)\n",
    "populator.load_associated_files([LABLE_FILE])\n",
    "populator.load_metadata_buffer(metadata_buf)\n",
    "populator.populate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFLite model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 (1, 10, 10, 255)\n",
      "404 (1, 20, 20, 255)\n",
      "403 (1, 40, 40, 255)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# get_tensor() returns a copy of the tensor data\n",
    "# use tensor() in order to get a pointer to the tensor\n",
    "for i in range(len(output_details)):\n",
    "    print(output_details[i]['index'], interpreter.get_tensor(output_details[i]['index']).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
