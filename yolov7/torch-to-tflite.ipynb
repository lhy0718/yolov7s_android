{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX to TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 22:11:40.419708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:40.419762: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/hanyong/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "2023-04-06 22:11:42.641864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-06 22:11:42.642184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642356: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642425: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642605: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642666: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-04-06 22:11:42.642680: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-04-06 22:11:42.643997: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "BackendIsNotSupposedToImplementIt",
     "evalue": "in user code:\n\n    File \"/home/hanyong/miniconda3/envs/yolo7/lib/python3.10/site-packages/onnx_tf/backend_tf_module.py\", line 99, in __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    File \"/home/hanyong/miniconda3/envs/yolo7/lib/python3.10/site-packages/onnx_tf/backend.py\", line 349, in _onnx_node_to_tensorflow_op  *\n        raise BackendIsNotSupposedToImplementIt(\"{} is not implemented.\".format(\n\n    BackendIsNotSupposedToImplementIt: EfficientNMS_TRT is not implemented.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBackendIsNotSupposedToImplementIt\u001b[0m         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m onnx_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(onnx_model_path)  \u001b[39m# load onnx model\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tf_rep \u001b[39m=\u001b[39m prepare(onnx_model)  \u001b[39m# prepare tf representation\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m tf_rep\u001b[39m.\u001b[39;49mexport_graph(tf_model_path)  \u001b[39m# export the model\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/onnx_tf/backend_rep.py:143\u001b[0m, in \u001b[0;36mTensorflowRep.export_graph\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Export backend representation to a Tensorflow proto file.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[39mThis function obtains the graph proto corresponding to the ONNX\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m:returns: none.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_module\u001b[39m.\u001b[39mis_export \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    140\u001b[0m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msave(\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_module,\n\u001b[1;32m    142\u001b[0m     path,\n\u001b[0;32m--> 143\u001b[0m     signatures\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtf_module\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m\u001b[39m.\u001b[39;49mget_concrete_function(\n\u001b[1;32m    144\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignatures))\n\u001b[1;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf_module\u001b[39m.\u001b[39mis_export \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:1264\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1265\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:1244\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1244\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m   1245\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1248\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2983\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2982\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2983\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2984\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd_call_context(cache_key\u001b[39m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   3293\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   3131\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   3132\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   3133\u001b[0m         args,\n\u001b[1;32m   3134\u001b[0m         kwargs,\n\u001b[1;32m   3135\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   3136\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   3137\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   3138\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   3139\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[1;32m   3140\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   3141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1163\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/eager/function.py:3831\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3826\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3828\u001b[0m \u001b[39m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m   3829\u001b[0m \u001b[39m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m   3830\u001b[0m \u001b[39m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m-> 3831\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolo7/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mBackendIsNotSupposedToImplementIt\u001b[0m: in user code:\n\n    File \"/home/hanyong/miniconda3/envs/yolo7/lib/python3.10/site-packages/onnx_tf/backend_tf_module.py\", line 99, in __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    File \"/home/hanyong/miniconda3/envs/yolo7/lib/python3.10/site-packages/onnx_tf/backend.py\", line 349, in _onnx_node_to_tensorflow_op  *\n        raise BackendIsNotSupposedToImplementIt(\"{} is not implemented.\".format(\n\n    BackendIsNotSupposedToImplementIt: EfficientNMS_TRT is not implemented.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model_path = \"yolov7-tiny.onnx\"\n",
    "tf_model_path = \"yolov7-tiny-tf\"\n",
    "\n",
    "onnx_model = onnx.load(onnx_model_path)  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
    "tf_rep.export_graph(tf_model_path)  # export the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 15:01:28.220579: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/assert_equal_5/Assert/AssertGuard/branch_executed/_212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 (1, 100, 4)\n",
      "417 (100, 1)\n",
      "438 (1,)\n",
      "output (1, 100)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size, width, height, channels = 1, 320, 320, 3\n",
    "input_shape = (batch_size, width, height, channels)\n",
    "\n",
    "model = tf.saved_model.load(tf_model_path)\n",
    "model.trainable = False\n",
    "\n",
    "input_tensor = tf.random.uniform(input_shape, 0, 255)\n",
    "out = model(images=input_tensor)\n",
    "for k in out:\n",
    "    print(k, out[k].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 15:05:29.061534: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-04-05 15:05:29.061606: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2023-04-05 15:05:29.061868: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: yolov7-tiny-tf\n",
      "2023-04-05 15:05:29.079767: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2023-04-05 15:05:29.079818: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: yolov7-tiny-tf\n",
      "2023-04-05 15:05:29.112069: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-04-05 15:05:29.332275: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: yolov7-tiny-tf\n",
      "2023-04-05 15:05:29.541171: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 479304 microseconds.\n",
      "2023-04-05 15:05:30.521983: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor convolution because it has fewer than 1024 elements (864).\n",
      "2023-04-05 15:05:30.522075: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor onnx_tf_prefix_/end2end/MatMul because it has fewer than 1024 elements (16).\n",
      "2023-04-05 15:05:30.522082: I tensorflow/lite/tools/optimize/quantize_weights.cc:217] Skipping quantization of tensor while2 that is not type float.\n",
      "2023-04-05 15:05:30.522086: I tensorflow/lite/tools/optimize/quantize_weights.cc:217] Skipping quantization of tensor while2 that is not type float.\n",
      "2023-04-05 15:05:30.522090: I tensorflow/lite/tools/optimize/quantize_weights.cc:234] Skipping quantization of tensor onnx_tf_prefix_/end2end/MatMul3 because it has no allocated buffer.\n",
      "2023-04-05 15:05:30.522095: I tensorflow/lite/tools/optimize/quantize_weights.cc:217] Skipping quantization of tensor Shape_22 that is not type float.\n",
      "2023-04-05 15:05:30.522100: I tensorflow/lite/tools/optimize/quantize_weights.cc:217] Skipping quantization of tensor Reshape_4 that is not type float.\n",
      "2023-04-05 15:05:30.522104: I tensorflow/lite/tools/optimize/quantize_weights.cc:217] Skipping quantization of tensor Shape_27 that is not type float.\n",
      "2023-04-05 15:05:30.522108: I tensorflow/lite/tools/optimize/quantize_weights.cc:234] Skipping quantization of tensor Reshape_5 because it has no allocated buffer.\n",
      "2023-04-05 15:05:30.522112: I tensorflow/lite/tools/optimize/quantize_weights.cc:217] Skipping quantization of tensor Shape_32 that is not type float.\n",
      "2023-04-05 15:05:30.522116: I tensorflow/lite/tools/optimize/quantize_weights.cc:217] Skipping quantization of tensor onnx_tf_prefix_/end2end/Shape_6 that is not type float.\n",
      "2023-04-05 15:05:30.578328: I tensorflow/lite/tools/optimize/quantize_weights.cc:234] Skipping quantization of tensor arg4 because it has no allocated buffer.\n",
      "2023-04-05 15:05:30.578383: I tensorflow/lite/tools/optimize/quantize_weights.cc:234] Skipping quantization of tensor arg3 because it has no allocated buffer.\n",
      "2023-04-05 15:05:30.578388: I tensorflow/lite/tools/optimize/quantize_weights.cc:234] Skipping quantization of tensor arg4 because it has no allocated buffer.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ['LD_LIBRARY_PATH'] = ' ${CONDA_PREFIX}/lib:${LD_LIBRARY_PATH}'\n",
    "\n",
    "tflite_model_path = 'yolov7-tiny.tflite'\n",
    "# tf_model_path = \"yolov7-tiny-tf\"\n",
    "\n",
    "# Convert\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "# model = tf.keras.models.load_model(tf_model_path, compile=False)\n",
    "# func = tf.function(model).get_concrete_function(\n",
    "#     images=tf.TensorSpec(input_shape, tf.float32)\n",
    "# )\n",
    "# converter = tf.lite.TFLiteConverter.from_concrete_functions([func])\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "\"\"\" ... \"\"\"\n",
    "\"\"\"Creates the metadata for an image classifier.\"\"\"\n",
    "\n",
    "LABLE_FILE = os.path.basename('label.txt')\n",
    "populator = _metadata.MetadataPopulator.with_model_file(tflite_model_path)\n",
    "populator.load_associated_files([LABLE_FILE])\n",
    "\n",
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = tflite_model_path.split('.')[0]\n",
    "\n",
    "# Creates input info.\n",
    "input_meta = _metadata_fb.TensorMetadataT()\n",
    "input_meta.name = \"image\"\n",
    "input_meta.description = (\"image\")\n",
    "input_meta.content = _metadata_fb.ContentT()\n",
    "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "input_meta.content.contentProperties.colorSpace = (\n",
    "    _metadata_fb.ColorSpaceType.RGB)\n",
    "input_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.ImageProperties)\n",
    "input_normalization = _metadata_fb.ProcessUnitT()\n",
    "input_normalization.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
    "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "input_normalization.options.mean = [127.5]\n",
    "input_normalization.options.std = [127.5]\n",
    "input_meta.processUnits = [input_normalization]\n",
    "input_stats = _metadata_fb.StatsT()\n",
    "input_stats.max = [255]\n",
    "input_stats.min = [0]\n",
    "input_meta.stats = input_stats\n",
    "\n",
    "# Creates output info.\n",
    "output_location_meta = _metadata_fb.TensorMetadataT()\n",
    "output_location_meta.name = \"location\"\n",
    "output_location_meta.description = \"The locations of the detected boxes.\"\n",
    "output_location_meta.content = _metadata_fb.ContentT()\n",
    "output_location_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.BoundingBoxProperties)\n",
    "output_location_meta.content.contentProperties = (\n",
    "    _metadata_fb.BoundingBoxPropertiesT())\n",
    "output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
    "output_location_meta.content.contentProperties.type = (\n",
    "    _metadata_fb.BoundingBoxType.BOUNDARIES)\n",
    "output_location_meta.content.contentProperties.coordinateType = (\n",
    "    _metadata_fb.CoordinateType.RATIO)\n",
    "output_location_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_location_meta.content.range.min = 2\n",
    "output_location_meta.content.range.max = 2\n",
    "\n",
    "output_class_meta = _metadata_fb.TensorMetadataT()\n",
    "output_class_meta.name = \"category\"\n",
    "output_class_meta.description = \"The categories of the detected boxes.\"\n",
    "output_class_meta.content = _metadata_fb.ContentT()\n",
    "output_class_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_class_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "output_class_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_class_meta.content.range.min = 2\n",
    "output_class_meta.content.range.max = 2\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = LABLE_FILE\n",
    "label_file.description = \"Label of objects that this model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_AXIS_LABELS\n",
    "output_class_meta.associatedFiles = [label_file]\n",
    "\n",
    "output_score_meta = _metadata_fb.TensorMetadataT()\n",
    "output_score_meta.name = \"score\"\n",
    "output_score_meta.description = \"The scores of the detected boxes.\"\n",
    "output_score_meta.content = _metadata_fb.ContentT()\n",
    "output_score_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_score_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "output_score_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_score_meta.content.range.min = 2\n",
    "output_score_meta.content.range.max = 2\n",
    "\n",
    "output_number_meta = _metadata_fb.TensorMetadataT()\n",
    "output_number_meta.name = \"number of detections\"\n",
    "output_number_meta.description = \"The number of the detected boxes.\"\n",
    "output_number_meta.content = _metadata_fb.ContentT()\n",
    "output_number_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_number_meta.content.contentProperties = (\n",
    "    _metadata_fb.FeaturePropertiesT())\n",
    "\n",
    "# Creates subgraph info.\n",
    "subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "subgraph.inputTensorMetadata = [input_meta]\n",
    "subgraph.outputTensorMetadata = [output_location_meta, output_score_meta, output_class_meta, output_number_meta]\n",
    "model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()\n",
    "\n",
    "populator.load_metadata_buffer(metadata_buf)\n",
    "populator.populate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFLite model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522 (1, 100, 4)\n",
      "548 (1,)\n",
      "544 (1, 100)\n",
      "535 (100, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# get_tensor() returns a copy of the tensor data\n",
    "# use tensor() in order to get a pointer to the tensor\n",
    "for i in range(4):\n",
    "    print(output_details[i]['index'], interpreter.get_tensor(output_details[i]['index']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
